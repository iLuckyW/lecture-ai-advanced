{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b9dd3c",
   "metadata": {},
   "source": [
    "Lecture: AI I - Advanced \n",
    "\n",
    "Previous:\n",
    "[**Chapter 1.2: Multilayer Perceptron**](../02_mlp.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c7fe0",
   "metadata": {},
   "source": [
    "# Exercise 1.2: Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ea8fd",
   "metadata": {},
   "source": [
    "> Hint: When doing the exercises put your solution in the designated \"Solution\" section:\n",
    "> ```python\n",
    "> # Solution (put your code here)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12dc950",
   "metadata": {},
   "source": [
    "## Task 1: Diabetes Regression with Multi-Layer Perceptron\n",
    "\n",
    "The diabetes dataset contains 442 samples with 10 baseline variables (age, sex, BMI, blood pressure, and 6 blood serum measurements). The target is a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "**Tasks**\n",
    "- Data Exploration & Understanding\n",
    "- Data preparation\n",
    "- Build Model a Multi-Layer Perceptron for regression\n",
    "- Train the model \n",
    "- Evaluate the model performance using appropriate regression metrics (e.g. MSE, MAE) and Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990749, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06833155, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286131, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04688253,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452873, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00422151,  0.00306441]], shape=(442, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prerequisites (don't edit this block)\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "x = diabetes.data\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d68e54",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_mean() got an unexpected keyword argument 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# normalize\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m x_norm = (x - \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m) / x.std(dim=\u001b[32m0\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# split into train and test data\u001b[39;00m\n\u001b[32m      9\u001b[39m train_data, test_data, train_label, test_label = train_test_split(x, y, test_size=\u001b[32m0.3\u001b[39m, random_state=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: _mean() got an unexpected keyword argument 'dim'"
     ]
    }
   ],
   "source": [
    "# Solution (put your code here)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# normalize\n",
    "x_norm = (x - x.mean(dim=0, keepdim=True)) / x.std(dim=0, keepdim=True)\n",
    "\n",
    "# split into train and test data\n",
    "train_data, test_data, train_label, test_label = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a601ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RegressionMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16594120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "model = RegressionMLP(input_dim=1)\n",
    "\n",
    "# Log the model architecture to TensorBoard\n",
    "writer = SummaryWriter(log_dir=f'./data/02_mlp/runs/run_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "writer.add_graph(model, x_norm[train_ids][:batch_size])\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d2584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case (don't edit this block)\n",
    "assert True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464ff25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Lecture: AI I - Advanced \n",
    "\n",
    "Next: [**Chapter 2.1: Regularization**](../../02_training/01_regularization.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-advanced",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
