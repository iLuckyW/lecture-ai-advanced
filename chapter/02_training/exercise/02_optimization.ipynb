{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b9dd3c",
   "metadata": {},
   "source": [
    "Lecture: AI I - Advanced \n",
    "\n",
    "Previous:\n",
    "[**Chapter 2.1: Optimization**](../02_optimization.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c7fe0",
   "metadata": {},
   "source": [
    "# Exercise 2.2: Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ea8fd",
   "metadata": {},
   "source": [
    "> Hint: When doing the exercises put your solution in the designated \"Solution\" section:\n",
    "> ```python\n",
    "> # Solution (put your code here)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645feb70",
   "metadata": {},
   "source": [
    "## Task 1: Diabetes Regression with an optimized Multi-Layer Perceptron \n",
    "\n",
    "The diabetes dataset contains 442 samples with 10 baseline variables (age, sex, BMI, blood pressure, and 6 blood serum measurements). The target is a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "**Tasks**\n",
    "- Data Exploration & Understanding\n",
    "- Data preparation\n",
    "- Build Model a Multi-Layer Perceptron for regression and optimize it with different optimization techniques and a hyperparameter search\n",
    "- Train the models and finde the best one\n",
    "- Evaluate the model performance using appropriate regression metrics (e.g. MSE, MAE) and Tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb1914ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites (don't edit this block)\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "x = diabetes.data\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6903fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution (put your code here)\n",
    "import torch\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).view(-1,1)\n",
    "n = len(x)\n",
    "\n",
    "x = (x - x.mean(dim=0, keepdim=True) / (x.std(dim=0, keepdim=True) + 1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6806ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches per epoch: 9\n",
      "Validation batches: 3\n",
      "Test batches: 3\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=f'./data/02_optimazation/runs/run_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "ids = torch.randperm(len(x))\n",
    "train_ids = ids[:int(n * .6)]\n",
    "val_ids = ids[int(n * .6):int(n * .8)]\n",
    "test_ids = ids[int(n * .8):]\n",
    "\n",
    "train_dataset = TensorDataset(x[train_ids], y[train_ids])\n",
    "val_dataset = TensorDataset(x[val_ids], y[val_ids])\n",
    "test_dataset = TensorDataset(x[test_ids], y[test_ids])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True  # Shuffle training data each epoch\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False  # Don't shuffle validation\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False  # Don't shuffle test\n",
    ")\n",
    "\n",
    "print(f\"Training batches per epoch: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e1518467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FlexibleClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Flexible neural network that can be configured with different architectures.\n",
    "    Supports variable depth and layer dimensions.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: Number of input features\n",
    "            hidden_dims: List of hidden layer dimensions, e.g., [64, 32]\n",
    "            output_dim: Number of output classes\n",
    "            dropout_rate: Dropout probability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build layers dynamically\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c9a00150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        train_loss += loss.item() * batch_X.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "    \n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            eval_loss += loss.item() * batch_X.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "    \n",
    "    avg_loss = eval_loss / len(data_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=100, lr=0.01, weight_decay=0.0, patience=15, trial=None):\n",
    "    \"\"\"Complete training loop\"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer) # Train\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion)  # Validate\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "    \n",
    "        if trial is not None:\n",
    "            trial.report(val_acc, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "    \n",
    "    return best_val_loss, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "666a637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize.\n",
    "    Returns the best validation accuracy for this hyperparameter configuration.\n",
    "    \"\"\"\n",
    "    # Define the search space\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 2)\n",
    "    hidden_dims = []\n",
    "    for i in range(n_layers):\n",
    "        dim = trial.suggest_categorical(f'hidden_dim_layer_{i}', [32, 64, 128, 256])\n",
    "        hidden_dims.append(dim)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-2, log=True)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)    \n",
    "    \n",
    "    # Training the model with the sampled hyperparameters\n",
    "    model = FlexibleClassifier(input_dim=10,hidden_dims=hidden_dims,output_dim=1,dropout_rate=dropout_rate)        \n",
    "    best_val_acc, _ = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        trial=trial  # For Optuna pruning\n",
    "    )\n",
    "    \n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2473487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-07 09:58:16,326]\u001b[0m A new study created in memory with name: diabetes_classification\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4cba9dbdcc465ab42b8c9df827e8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-07 09:58:17,307]\u001b[0m Trial 0 finished with value: 3053.7963423295455 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 256, 'hidden_dim_layer_1': 128, 'weight_decay': 0.0011835969029247513, 'learning_rate': 0.0041236634227404855, 'dropout_rate': 0.3100856934720849}. Best is trial 0 with value: 3053.7963423295455.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:19,104]\u001b[0m Trial 1 finished with value: 2972.847323330966 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 256, 'hidden_dim_layer_1': 256, 'weight_decay': 4.978067450993893e-05, 'learning_rate': 0.004272450502623133, 'dropout_rate': 0.2651938885878364}. Best is trial 1 with value: 2972.847323330966.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:20,032]\u001b[0m Trial 2 finished with value: 3088.8168501420455 and parameters: {'n_layers': 1, 'hidden_dim_layer_0': 256, 'weight_decay': 0.00023310734604919177, 'learning_rate': 0.007847714660187102, 'dropout_rate': 0.11738679064255247}. Best is trial 1 with value: 2972.847323330966.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:21,428]\u001b[0m Trial 3 finished with value: 3027.9230513139205 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 256, 'hidden_dim_layer_1': 256, 'weight_decay': 0.0005325432278842639, 'learning_rate': 0.0016363388781724054, 'dropout_rate': 0.05429986250234714}. Best is trial 1 with value: 2972.847323330966.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:22,773]\u001b[0m Trial 4 finished with value: 29587.911044034092 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 64, 'hidden_dim_layer_1': 32, 'weight_decay': 0.0028745029512393, 'learning_rate': 2.7495850901716878e-05, 'dropout_rate': 0.22345485765840467}. Best is trial 1 with value: 2972.847323330966.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:23,840]\u001b[0m Trial 5 finished with value: 29363.170276988636 and parameters: {'n_layers': 1, 'hidden_dim_layer_0': 64, 'weight_decay': 4.335654432719207e-05, 'learning_rate': 0.0001317547521791292, 'dropout_rate': 0.23629031180485954}. Best is trial 1 with value: 2972.847323330966.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:24,925]\u001b[0m Trial 6 finished with value: 3267.209161931818 and parameters: {'n_layers': 1, 'hidden_dim_layer_0': 128, 'weight_decay': 0.00012743835288831572, 'learning_rate': 0.003281480438943006, 'dropout_rate': 0.4942652655122299}. Best is trial 1 with value: 2972.847323330966.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:25,973]\u001b[0m Trial 7 finished with value: 29693.884765625 and parameters: {'n_layers': 1, 'hidden_dim_layer_0': 32, 'weight_decay': 0.009592118600966473, 'learning_rate': 4.5961913430774814e-05, 'dropout_rate': 0.47015462444306283}. Best is trial 1 with value: 2972.847323330966.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:26,497]\u001b[0m Trial 8 finished with value: 2925.0709339488635 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 1.0086875691091195e-05, 'learning_rate': 0.03827581030488796, 'dropout_rate': 0.1867992275766469}. Best is trial 8 with value: 2925.0709339488635.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:27,648]\u001b[0m Trial 9 finished with value: 4059.0009321732955 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 64, 'hidden_dim_layer_1': 64, 'weight_decay': 0.005668264031747635, 'learning_rate': 0.00045289476311863964, 'dropout_rate': 0.055333826855156976}. Best is trial 8 with value: 2925.0709339488635.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:28,202]\u001b[0m Trial 10 finished with value: 3038.9134410511365 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 1.237798391229792e-05, 'learning_rate': 0.08686081174192185, 'dropout_rate': 0.3711201504982126}. Best is trial 8 with value: 2925.0709339488635.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:28,701]\u001b[0m Trial 11 finished with value: 2923.615167791193 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 1.0144200047080233e-05, 'learning_rate': 0.05712840923684309, 'dropout_rate': 0.16438550545007816}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:29,234]\u001b[0m Trial 12 finished with value: 3005.288973721591 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 1.190525810759158e-05, 'learning_rate': 0.08920465750342511, 'dropout_rate': 0.1462650512411952}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:29,909]\u001b[0m Trial 13 finished with value: 2932.592595880682 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 3.515684335313827e-05, 'learning_rate': 0.024535914424171995, 'dropout_rate': 0.1516190535623645}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:30,641]\u001b[0m Trial 14 finished with value: 2938.5702015269885 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 64, 'weight_decay': 1.113712949424985e-05, 'learning_rate': 0.021929045223067687, 'dropout_rate': 0.17985661660550703}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:31,572]\u001b[0m Trial 15 finished with value: 2929.7490234375 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 32, 'hidden_dim_layer_1': 32, 'weight_decay': 8.840114922492324e-05, 'learning_rate': 0.021720793216562343, 'dropout_rate': 0.010482021070503361}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:33,157]\u001b[0m Trial 16 finished with value: 3360.3749778053975 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 128, 'weight_decay': 2.6732640731813954e-05, 'learning_rate': 0.0005931095790031287, 'dropout_rate': 0.32811755956657496}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:33,673]\u001b[0m Trial 17 finished with value: 3089.4579856178975 and parameters: {'n_layers': 1, 'hidden_dim_layer_0': 128, 'weight_decay': 1.9761429598241637e-05, 'learning_rate': 0.02649126965440809, 'dropout_rate': 0.09989717201076917}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:32,938]\u001b[0m Trial 18 finished with value: 3065.5490278764205 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 0.00010252102399827749, 'learning_rate': 0.09903174402488531, 'dropout_rate': 0.40185784940886804}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:33,461]\u001b[0m Trial 19 finished with value: 3001.1158558238635 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 32, 'hidden_dim_layer_1': 256, 'weight_decay': 0.0004889020391023514, 'learning_rate': 0.01032686114690201, 'dropout_rate': 0.1966678762692442}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:34,583]\u001b[0m Trial 20 finished with value: 28044.644886363636 and parameters: {'n_layers': 1, 'hidden_dim_layer_0': 128, 'weight_decay': 0.00023608966247302542, 'learning_rate': 0.0001786453529005921, 'dropout_rate': 0.29146702997091206}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:35,221]\u001b[0m Trial 21 finished with value: 2954.932373046875 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 32, 'hidden_dim_layer_1': 32, 'weight_decay': 7.18561447040876e-05, 'learning_rate': 0.04133070009638031, 'dropout_rate': 0.021734168147932192}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:36,137]\u001b[0m Trial 22 finished with value: 3013.9469770951705 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 32, 'hidden_dim_layer_1': 32, 'weight_decay': 2.2439228502853862e-05, 'learning_rate': 0.010324895051112115, 'dropout_rate': 0.00209731934266128}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:36,857]\u001b[0m Trial 23 finished with value: 2953.2466264204545 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 32, 'hidden_dim_layer_1': 32, 'weight_decay': 0.0001325895409624741, 'learning_rate': 0.039542361304733153, 'dropout_rate': 0.08479510331861595}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:37,367]\u001b[0m Trial 24 finished with value: 3096.029541015625 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 32, 'hidden_dim_layer_1': 32, 'weight_decay': 1.8421280631900302e-05, 'learning_rate': 0.015910173264402246, 'dropout_rate': 0.18988044647812058}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:37,809]\u001b[0m Trial 25 finished with value: 2954.6244895241475 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 5.0857671746399646e-05, 'learning_rate': 0.04473171386975263, 'dropout_rate': 0.1549106847433678}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:39,164]\u001b[0m Trial 26 finished with value: 3083.4067604758525 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 32, 'hidden_dim_layer_1': 128, 'weight_decay': 0.0011647140823454179, 'learning_rate': 0.0022280470073338795, 'dropout_rate': 0.055586599769483665}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:39,953]\u001b[0m Trial 27 finished with value: 3043.0472523082385 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 64, 'hidden_dim_layer_1': 64, 'weight_decay': 8.339556320378729e-05, 'learning_rate': 0.006697195841402439, 'dropout_rate': 0.2642088086498665}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:40,389]\u001b[0m Trial 28 finished with value: 2966.7232555042615 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 32, 'weight_decay': 1.6755990699661286e-05, 'learning_rate': 0.050960199240803215, 'dropout_rate': 0.12319142715465654}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:40,982]\u001b[0m Trial 29 finished with value: 2962.5569291548295 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 256, 'hidden_dim_layer_1': 256, 'weight_decay': 3.208475285508174e-05, 'learning_rate': 0.01666806811368074, 'dropout_rate': 0.21111830295821626}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:42,314]\u001b[0m Trial 30 finished with value: 3249.135320490057 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 32, 'hidden_dim_layer_1': 256, 'weight_decay': 0.0013509128315949074, 'learning_rate': 0.0009786944512388896, 'dropout_rate': 0.3316353160321496}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:42,830]\u001b[0m Trial 31 finished with value: 2931.030917080966 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 3.563170925117129e-05, 'learning_rate': 0.02416731498747817, 'dropout_rate': 0.16121176496653344}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:43,492]\u001b[0m Trial 32 finished with value: 3038.2319779829545 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 1.0478062636688822e-05, 'learning_rate': 0.00420179057240893, 'dropout_rate': 0.17479661280768066}. Best is trial 11 with value: 2923.615167791193.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:44,017]\u001b[0m Trial 33 finished with value: 2921.869140625 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 5.920061114167314e-05, 'learning_rate': 0.06368617250371787, 'dropout_rate': 0.12300892200126566}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:44,349]\u001b[0m Trial 34 finished with value: 2935.638427734375 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 256, 'hidden_dim_layer_1': 256, 'weight_decay': 6.347329768550866e-05, 'learning_rate': 0.06640559502947889, 'dropout_rate': 0.0932591217807542}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:45,457]\u001b[0m Trial 35 finished with value: 2957.6543190696025 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 32, 'weight_decay': 0.00017617286010082676, 'learning_rate': 0.007197755007125815, 'dropout_rate': 0.12544798000112584}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:46,239]\u001b[0m Trial 36 finished with value: 2988.8001598011365 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 256, 'hidden_dim_layer_1': 128, 'weight_decay': 0.00035479305612241835, 'learning_rate': 0.01306989406798608, 'dropout_rate': 0.07471640348449919}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:47,007]\u001b[0m Trial 37 finished with value: 3019.7505992542615 and parameters: {'n_layers': 1, 'hidden_dim_layer_0': 128, 'weight_decay': 5.358336018243961e-05, 'learning_rate': 0.03169461363070035, 'dropout_rate': 0.23323291219498252}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:47,643]\u001b[0m Trial 38 finished with value: 2983.9072265625 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 64, 'hidden_dim_layer_1': 256, 'weight_decay': 1.6150929368696112e-05, 'learning_rate': 0.0522299173657309, 'dropout_rate': 0.029615038072114477}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:49,144]\u001b[0m Trial 39 finished with value: 29676.788529829544 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 64, 'weight_decay': 0.0001776486789703192, 'learning_rate': 1.1007451065810074e-05, 'dropout_rate': 0.2517553261247789}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:50,236]\u001b[0m Trial 40 finished with value: 3078.350430575284 and parameters: {'n_layers': 1, 'hidden_dim_layer_0': 256, 'weight_decay': 0.000996609973800557, 'learning_rate': 0.005817449515744488, 'dropout_rate': 0.11720877861935547}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:50,785]\u001b[0m Trial 41 finished with value: 2951.6513893821025 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 4.002762737827042e-05, 'learning_rate': 0.02133426059459692, 'dropout_rate': 0.20600095150493206}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:51,277]\u001b[0m Trial 42 finished with value: 2991.0156028053975 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 2.671116168037872e-05, 'learning_rate': 0.06589041671450407, 'dropout_rate': 0.16375259893295302}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:51,731]\u001b[0m Trial 43 finished with value: 2942.292169744318 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 1.5201613629801906e-05, 'learning_rate': 0.03842636485630759, 'dropout_rate': 0.1389105431819711}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:52,664]\u001b[0m Trial 44 finished with value: 3011.7359508167615 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 9.888409442097691e-05, 'learning_rate': 0.0024408242925158825, 'dropout_rate': 0.23357821170284546}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:53,030]\u001b[0m Trial 45 finished with value: 2959.3399547230115 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 64, 'hidden_dim_layer_1': 256, 'weight_decay': 2.8953166236433106e-05, 'learning_rate': 0.06522515978969491, 'dropout_rate': 0.06737792908050044}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:53,545]\u001b[0m Trial 46 finished with value: 2930.3743785511365 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 256, 'weight_decay': 4.244364422860645e-05, 'learning_rate': 0.028221568888037184, 'dropout_rate': 0.28210551680255413}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:54,494]\u001b[0m Trial 47 finished with value: 2953.0558638139205 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 128, 'weight_decay': 4.634605287262001e-05, 'learning_rate': 0.011864782432797396, 'dropout_rate': 0.27942900688601524}. Best is trial 33 with value: 2921.869140625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:55,108]\u001b[0m Trial 48 finished with value: 2905.8095481178975 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 128, 'hidden_dim_layer_1': 32, 'weight_decay': 1.3492792323410199e-05, 'learning_rate': 0.09824450862761282, 'dropout_rate': 0.35902714100253125}. Best is trial 48 with value: 2905.8095481178975.\u001b[0m\n",
      "\u001b[32m[I 2026-02-07 09:58:55,605]\u001b[0m Trial 49 finished with value: 2913.627019708807 and parameters: {'n_layers': 2, 'hidden_dim_layer_0': 32, 'hidden_dim_layer_1': 32, 'weight_decay': 1.3138180502157295e-05, 'learning_rate': 0.07721511415833919, 'dropout_rate': 0.40326666758268176}. Best is trial 48 with value: 2905.8095481178975.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name='diabetes_classification',\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=10\n",
    "    )\n",
    ")\n",
    "\n",
    "n_trials = 50\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "05a472fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Lowest validation loss: 2949.5024\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "\n",
    "n_layers = best_params['n_layers']\n",
    "hidden_dims = [best_params[f'hidden_dim_layer_{i}'] for i in range(n_layers)]\n",
    "\n",
    "best_model = FlexibleClassifier(\n",
    "    input_dim=10,\n",
    "    hidden_dims=hidden_dims,\n",
    "    output_dim=1,\n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ")\n",
    "\n",
    "best_val_loss, _ = train_model(\n",
    "    model=best_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    lr=best_params['learning_rate'],\n",
    "    weight_decay=best_params['weight_decay'],\n",
    ")\n",
    "\n",
    "print(f\"  Lowest validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bc3d26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case (don't edit this block)\n",
    "assert True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464ff25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Lecture: AI I - Advanced \n",
    "\n",
    "Next: [**Chapter 2.3: Ensemble learning**](../03_ensemble.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-advanced",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
