{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b9dd3c",
   "metadata": {},
   "source": [
    "Lecture: AI I - Advanced \n",
    "\n",
    "Previous:\n",
    "[**Chapter 2.3: Ensemble learning**](../03_ensemble.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c7fe0",
   "metadata": {},
   "source": [
    "# Exercise 2.3: Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ea8fd",
   "metadata": {},
   "source": [
    "> Hint: When doing the exercises put your solution in the designated \"Solution\" section:\n",
    "> ```python\n",
    "> # Solution (put your code here)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8553dc",
   "metadata": {},
   "source": [
    "## Task 1: Diabetes Regression with multiple Multi-Layer Perceptron\n",
    "\n",
    "The diabetes dataset contains 442 samples with 10 baseline variables (age, sex, BMI, blood pressure, and 6 blood serum measurements). The target is a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "**Tasks**\n",
    "- Data Exploration & Understanding\n",
    "- Data preparation\n",
    "- Build Models: multiple Multi-Layer Perceptrons for regression (at least 3 with different architectures)\n",
    "- Train the models \n",
    "- Construct an ensemble model from the individual models\n",
    "- Evaluate the model performance using appropriate regression metrics (e.g. MSE, MAE) and Tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73228232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites (don't edit this block)\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "x = diabetes.data\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "024600fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)  # set random seed for reproducibility\n",
    "\n",
    "x_scaled = StandardScaler().fit_transform(x)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    x_scaled, y, test_size=0.4, random_state=42\n",
    ")\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(TensorDataset(torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32).view(-1,1)), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(torch.tensor(x_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32).view(-1,1)), batch_size=batch_size)\n",
    "test_loader = DataLoader(TensorDataset(torch.tensor(x_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).view(-1,1)), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0548c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FunnelNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Funnel architecture: Wide → Narrow\n",
    "    Starts with many neurons and gradually reduces.\n",
    "    Good for learning broad features then focusing.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=10, output_dim=1):\n",
    "        super().__init__()\n",
    "        # 128 → 64 → 32 (funnel shape)\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, output_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6987bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedFunnelNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Inverted Funnel architecture: Narrow → Wide\n",
    "    Starts focused and gradually expands representation.\n",
    "    Builds increasingly complex features.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=10, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 128)\n",
    "        self.fc4 = nn.Linear(128, output_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8f82703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrickNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Brick architecture: Constant width\n",
    "    All hidden layers have the same number of neurons.\n",
    "    Good for maintaining consistent representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=10, output_dim=1):\n",
    "        super().__init__()\n",
    "        # 64 → 64 → 64 (brick/constant shape)\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, output_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eaafa333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * batch_X.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "    \n",
    "    return train_loss / len(train_loader.dataset), correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            eval_loss += loss.item() * batch_X.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "    \n",
    "    return eval_loss / len(data_loader.dataset), correct / total\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=150, lr=0.01):\n",
    "    \"\"\"Train a single model\"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience = 20\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "    \n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "843f925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funnel Best Validation Loss: 2507.8000\n",
      "Inverted Funnel Best Validation Loss: 2519.5131\n",
      "Brick Best Validation Loss: 2598.9504\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Funnel\": FunnelNetwork(),\n",
    "    \"Inverted Funnel\": InvertedFunnelNetwork(),\n",
    "    \"Brick\": BrickNetwork()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    best_val_loss = train_model(model, train_loader, val_loader)\n",
    "    print(f\"{name} Best Validation Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case (don't edit this block)\n",
    "assert True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464ff25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Lecture: AI I - Advanced \n",
    "\n",
    "Next: [**Chapter 3.1: PyTorch Lightning**](../../03_advanced/01_lightning.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-advanced",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
